{"cells":[{"cell_type":"markdown","id":"enhanced-delivery","metadata":{"id":"enhanced-delivery"},"source":["## Meghana "]},{"cell_type":"code","execution_count":null,"id":"recreational-chapel","metadata":{"id":"recreational-chapel"},"outputs":[],"source":["import nltk\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"id":"approved-cologne","metadata":{"id":"approved-cologne","outputId":"7ab065f0-2c54-4f2a-92d5-e49cfde0deed"},"outputs":[{"name":"stdout","output_type":"stream","text":["NLP.1.ipynb\r\n","NLP.2.ipynb\r\n","\u001b[34mNLP_Code\u001b[m\u001b[m/\r\n","TwitterHate.csv\r\n","Untitled.ipynb\r\n","sda___dsai___natural_language_processing_-28nlp-29___live_class-20210901_0759-1_1630503031.arf\r\n","text.txt\r\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":null,"id":"violent-province","metadata":{"id":"violent-province","outputId":"67d6d128-4794-45bc-95f7-aa59fcc3c1d4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>@user when a father is dysfunctional and is s...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>@user @user thanks for #lyft credit i can't us...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>bihday your majesty</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>#model   i love u take with u all the time in ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>factsguide: society now    #motivation</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  label                                              tweet\n","0   1      0   @user when a father is dysfunctional and is s...\n","1   2      0  @user @user thanks for #lyft credit i can't us...\n","2   3      0                                bihday your majesty\n","3   4      0  #model   i love u take with u all the time in ...\n","4   5      0             factsguide: society now    #motivation"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"TwitterHate.csv\")\n","df.head()"]},{"cell_type":"code","execution_count":null,"id":"ordered-dublin","metadata":{"id":"ordered-dublin","outputId":"b5d9429f-ed29-42a7-e532-48705f728953"},"outputs":[{"data":{"text/plain":["0    29720\n","1     2242\n","Name: label, dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.label.value_counts()"]},{"cell_type":"code","execution_count":null,"id":"handy-barrel","metadata":{"id":"handy-barrel","outputId":"cdd16029-4e2e-4c3f-e952-a9e794582340"},"outputs":[{"data":{"text/plain":["0    0.929854\n","1    0.070146\n","Name: label, dtype: float64"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["df.label.value_counts(normalize = True)"]},{"cell_type":"code","execution_count":null,"id":"federal-consideration","metadata":{"id":"federal-consideration","outputId":"eff37496-5cb2-4ae3-98ae-775bf94ae203"},"outputs":[{"name":"stdout","output_type":"stream","text":["[' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run', \"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\", '  bihday your majesty', '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ', ' factsguide: society now    #motivation']\n"]}],"source":["tweets = list(df.tweet)\n","print(tweets[:5])"]},{"cell_type":"code","execution_count":null,"id":"daily-student","metadata":{"id":"daily-student","outputId":"4600c600-3d93-4cc6-9cfb-e8f44e9044f8"},"outputs":[{"data":{"text/plain":["\"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\""]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["tweets[1]"]},{"cell_type":"markdown","id":"organized-classroom","metadata":{"id":"organized-classroom"},"source":["### Remove contractions"]},{"cell_type":"code","execution_count":null,"id":"identified-surfing","metadata":{"id":"identified-surfing","outputId":"d99143f9-519a-437f-ab52-0308806a8e01"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original text: @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\n","Expanded_text: @user @user thanks for #lyft credit i cannot use because they do not offer wheelchair vans in pdx. #disapointed #getthanked\n"]}],"source":["import contractions\n","\n","text = tweets[1]\n","expanded_words = []   \n","\n","for word in text.split():\n","  # using contractions.fix to expand the shotened words\n","  expanded_words.append(contractions.fix(word))   \n","    \n","expanded_text = ' '.join(expanded_words)\n","print('Original text: ' + text)\n","print('Expanded_text: ' + expanded_text)"]},{"cell_type":"code","execution_count":null,"id":"nearby-boxing","metadata":{"id":"nearby-boxing","outputId":"c640d861-bfaa-445f-c94b-355d41532106"},"outputs":[{"data":{"text/plain":["31962"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["len(tweets)"]},{"cell_type":"code","execution_count":null,"id":"popular-ethics","metadata":{"id":"popular-ethics","outputId":"c8313599-2926-4860-b758-d5c20cd30dc4"},"outputs":[{"data":{"text/plain":["31962"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["no_cont_tweets = []   \n","\n","\n","for word in tweets:\n","  # using contractions.fix to expand the shotened words\n","  no_cont_tweets.append(contractions.fix(word))   \n","    \n","    \n","len(no_cont_tweets)"]},{"cell_type":"markdown","id":"relevant-triangle","metadata":{"id":"relevant-triangle"},"source":["### Lower case"]},{"cell_type":"code","execution_count":null,"id":"theoretical-physiology","metadata":{"id":"theoretical-physiology","outputId":"086de822-3bdc-4db0-91b4-ff8bf09b5454"},"outputs":[{"name":"stdout","output_type":"stream","text":[" @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run\n","\n","-----------\n","@user @user thanks for #lyft credit i cannot use because they do not offer wheelchair vans in pdx.    #disapointed #getthanked\n","\n","-----------\n","  bihday your majesty\n","\n","-----------\n","#model   i love you take with you all the time in urð±!!! ðððð","ð¦ð¦ð¦  \n","\n","-----------\n"," factsguide: society now    #motivation\n","\n","-----------\n"]}],"source":["new_tweets = [x.lower() for x in no_cont_tweets]\n","for t in new_tweets[:5]:\n","    print(t)\n","    print(\"\\n-----------\")"]},{"cell_type":"markdown","id":"fatty-hardware","metadata":{"id":"fatty-hardware"},"source":["### Removing @Users & URLs"]},{"cell_type":"code","execution_count":null,"id":"ignored-renewal","metadata":{"id":"ignored-renewal"},"outputs":[],"source":["import re"]},{"cell_type":"code","execution_count":null,"id":"placed-merchant","metadata":{"id":"placed-merchant","outputId":"c1f9d2d2-7079-4789-d081-bd539ba7b614"},"outputs":[{"data":{"text/plain":["' has an amazing account'"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["re.sub(\"@\\w+\",\"\", \"@Meghana has an amazing account\")"]},{"cell_type":"code","execution_count":null,"id":"conventional-ribbon","metadata":{"id":"conventional-ribbon","outputId":"b05b66fe-f50d-45f9-befb-981990d362d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run\n","\n","-----------\n","  thanks for #lyft credit i cannot use because they do not offer wheelchair vans in pdx.    #disapointed #getthanked\n","\n","-----------\n","  bihday your majesty\n","\n","-----------\n","#model   i love you take with you all the time in urð±!!! ðððð","ð¦ð¦ð¦  \n","\n","-----------\n"," factsguide: society now    #motivation\n","\n","-----------\n"]}],"source":["new_tweets = [re.sub(\"@\\w+\",\"\", x) for x in new_tweets]\n","\n","for t in new_tweets[:5]:\n","    print(t)\n","    print(\"\\n-----------\")"]},{"cell_type":"code","execution_count":null,"id":"indie-louisville","metadata":{"id":"indie-louisville","outputId":"5a17a9f7-96a0-48b4-8b71-2c404762534d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of urls in tweets: 22\n"]}],"source":["n = 0\n","m = 0\n","for x in new_tweets:\n","    n += (np.sum(len(re.findall(\"www.\\w+.\\w+\", x))))\n","    m += (np.sum(len(re.findall(\"\\w+://\\S+\",x))))\n","    \n","    \n","print(\"Number of urls in tweets:\", n+m)"]},{"cell_type":"code","execution_count":null,"id":"gentle-compact","metadata":{"id":"gentle-compact"},"outputs":[],"source":["new_tweets = [re.sub(\"www.\\w+.\\w+\",\"\", x) for x in new_tweets]\n","\n","new_tweets = [re.sub(\"\\w+://\\S+\",\"\", x) for x in new_tweets]"]},{"cell_type":"code","execution_count":null,"id":"anonymous-humanitarian","metadata":{"id":"anonymous-humanitarian","outputId":"3129c0dc-7ba7-4d17-b7a9-276aee935589"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of urls in tweets after using sub : 0\n"]}],"source":["#After replacing urls with \"\"\n","n = 0\n","m = 0\n","for x in new_tweets:\n","    n += (np.sum(len(re.findall(\"www.\\w+.\\w+\", x))))\n","    m += (np.sum(len(re.findall(\"\\w+://\\S+\",x))))\n","    \n","    \n","print(\"Number of urls in tweets after using sub :\", n+m)"]},{"cell_type":"markdown","id":"prepared-telephone","metadata":{"id":"prepared-telephone"},"source":["### Using TweetTokenizer to tokenize the tweets into individual terms."]},{"cell_type":"code","execution_count":null,"id":"flush-preview","metadata":{"id":"flush-preview"},"outputs":[],"source":["from nltk import TweetTokenizer"]},{"cell_type":"code","execution_count":null,"id":"bearing-comfort","metadata":{"id":"bearing-comfort","outputId":"d8d8b05c-9e07-4279-d410-06ca319e0cb5"},"outputs":[{"name":"stdout","output_type":"stream","text":["['when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#run']\n"]}],"source":["tkn = TweetTokenizer()\n","print(tkn.tokenize(new_tweets[0]))"]},{"cell_type":"code","execution_count":null,"id":"polished-arlington","metadata":{"id":"polished-arlington","outputId":"26c6ca66-e1bb-4ea7-ebfd-3fb070ae4827"},"outputs":[{"name":"stdout","output_type":"stream","text":["['when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#run']\n","['just', 'booked', 'our', 'trip', 'to', 'europeð', '\\x9f', '\\x91', '\\x8f', 'ð', '\\x9f', '\\x8f', '»', 'â', '\\x9c', '\\x88', 'ï', '¸', '\\x8f', '#travelwise', '#europe2016', '#london', '#paris']\n"]}],"source":["tweet_token = [tkn.tokenize(sent) for sent in new_tweets]\n","print(tweet_token[0])\n","print(tweet_token[1000])"]},{"cell_type":"markdown","id":"continuous-intent","metadata":{"id":"continuous-intent"},"source":["### Remove stop words"]},{"cell_type":"code","execution_count":null,"id":"reserved-dodge","metadata":{"id":"reserved-dodge"},"outputs":[],"source":["from nltk.corpus import stopwords\n","from string import punctuation"]},{"cell_type":"code","execution_count":null,"id":"engaging-biology","metadata":{"id":"engaging-biology","outputId":"299b930d-9c3f-4387-d1e9-03952b33a55f"},"outputs":[{"data":{"text/plain":["'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["punctuation"]},{"cell_type":"code","execution_count":null,"id":"happy-azerbaijan","metadata":{"id":"happy-azerbaijan"},"outputs":[],"source":["stop_nltk = stopwords.words(\"english\")\n","stop_punct = list(punctuation)"]},{"cell_type":"code","execution_count":null,"id":"motivated-headset","metadata":{"id":"motivated-headset","outputId":"09065245-bc66-418e-e19a-ffd35a16fc2f"},"outputs":[{"data":{"text/plain":["['i',\n"," 'me',\n"," 'my',\n"," 'myself',\n"," 'we',\n"," 'our',\n"," 'ours',\n"," 'ourselves',\n"," 'you',\n"," \"you're\",\n"," \"you've\",\n"," \"you'll\",\n"," \"you'd\",\n"," 'your',\n"," 'yours',\n"," 'yourself',\n"," 'yourselves',\n"," 'he',\n"," 'him',\n"," 'his',\n"," 'himself',\n"," 'she',\n"," \"she's\",\n"," 'her',\n"," 'hers',\n"," 'herself',\n"," 'it',\n"," \"it's\",\n"," 'its',\n"," 'itself',\n"," 'they',\n"," 'them',\n"," 'their',\n"," 'theirs',\n"," 'themselves',\n"," 'what',\n"," 'which',\n"," 'who',\n"," 'whom',\n"," 'this',\n"," 'that',\n"," \"that'll\",\n"," 'these',\n"," 'those',\n"," 'am',\n"," 'is',\n"," 'are',\n"," 'was',\n"," 'were',\n"," 'be',\n"," 'been',\n"," 'being',\n"," 'have',\n"," 'has',\n"," 'had',\n"," 'having',\n"," 'do',\n"," 'does',\n"," 'did',\n"," 'doing',\n"," 'a',\n"," 'an',\n"," 'the',\n"," 'and',\n"," 'but',\n"," 'if',\n"," 'or',\n"," 'because',\n"," 'as',\n"," 'until',\n"," 'while',\n"," 'of',\n"," 'at',\n"," 'by',\n"," 'for',\n"," 'with',\n"," 'about',\n"," 'against',\n"," 'between',\n"," 'into',\n"," 'through',\n"," 'during',\n"," 'before',\n"," 'after',\n"," 'above',\n"," 'below',\n"," 'to',\n"," 'from',\n"," 'up',\n"," 'down',\n"," 'in',\n"," 'out',\n"," 'on',\n"," 'off',\n"," 'over',\n"," 'under',\n"," 'again',\n"," 'further',\n"," 'then',\n"," 'once',\n"," 'here',\n"," 'there',\n"," 'when',\n"," 'where',\n"," 'why',\n"," 'how',\n"," 'all',\n"," 'any',\n"," 'both',\n"," 'each',\n"," 'few',\n"," 'more',\n"," 'most',\n"," 'other',\n"," 'some',\n"," 'such',\n"," 'no',\n"," 'nor',\n"," 'not',\n"," 'only',\n"," 'own',\n"," 'same',\n"," 'so',\n"," 'than',\n"," 'too',\n"," 'very',\n"," 's',\n"," 't',\n"," 'can',\n"," 'will',\n"," 'just',\n"," 'don',\n"," \"don't\",\n"," 'should',\n"," \"should've\",\n"," 'now',\n"," 'd',\n"," 'll',\n"," 'm',\n"," 'o',\n"," 're',\n"," 've',\n"," 'y',\n"," 'ain',\n"," 'aren',\n"," \"aren't\",\n"," 'couldn',\n"," \"couldn't\",\n"," 'didn',\n"," \"didn't\",\n"," 'doesn',\n"," \"doesn't\",\n"," 'hadn',\n"," \"hadn't\",\n"," 'hasn',\n"," \"hasn't\",\n"," 'haven',\n"," \"haven't\",\n"," 'isn',\n"," \"isn't\",\n"," 'ma',\n"," 'mightn',\n"," \"mightn't\",\n"," 'mustn',\n"," \"mustn't\",\n"," 'needn',\n"," \"needn't\",\n"," 'shan',\n"," \"shan't\",\n"," 'shouldn',\n"," \"shouldn't\",\n"," 'wasn',\n"," \"wasn't\",\n"," 'weren',\n"," \"weren't\",\n"," 'won',\n"," \"won't\",\n"," 'wouldn',\n"," \"wouldn't\"]"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["stop_nltk"]},{"cell_type":"code","execution_count":null,"id":"circular-cylinder","metadata":{"id":"circular-cylinder","outputId":"d79b3a07-ef2b-4cfb-9fca-d8cda428bc35"},"outputs":[{"data":{"text/plain":["['!',\n"," '\"',\n"," '#',\n"," '$',\n"," '%',\n"," '&',\n"," \"'\",\n"," '(',\n"," ')',\n"," '*',\n"," '+',\n"," ',',\n"," '-',\n"," '.',\n"," '/',\n"," ':',\n"," ';',\n"," '<',\n"," '=',\n"," '>',\n"," '?',\n"," '@',\n"," '[',\n"," '\\\\',\n"," ']',\n"," '^',\n"," '_',\n"," '`',\n"," '{',\n"," '|',\n"," '}',\n"," '~']"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["stop_punct"]},{"cell_type":"code","execution_count":null,"id":"medical-madonna","metadata":{"id":"medical-madonna"},"outputs":[],"source":["stop_punct.extend(['...','``',\"''\",\"..\"])"]},{"cell_type":"code","execution_count":null,"id":"automotive-checkout","metadata":{"id":"automotive-checkout"},"outputs":[],"source":["stop_context = ['rt', 'amp','rts','retweet']"]},{"cell_type":"code","execution_count":null,"id":"primary-peter","metadata":{"id":"primary-peter"},"outputs":[],"source":["final_stop = set(stop_punct) | set(stop_context) | set(stop_nltk)"]},{"cell_type":"code","execution_count":null,"id":"dirty-egypt","metadata":{"id":"dirty-egypt"},"outputs":[],"source":["final_stop = list(final_stop)"]},{"cell_type":"code","execution_count":null,"id":"handed-darkness","metadata":{"id":"handed-darkness"},"outputs":[],"source":["def del_stop(sent):\n","    return [re.sub(\"#\",\"\",term) for term in sent if ((term not in final_stop) & (len(term)>1))]"]},{"cell_type":"code","execution_count":null,"id":"closing-scanner","metadata":{"id":"closing-scanner","outputId":"95f1994a-bcae-4889-dbe2-080bff9f52b8"},"outputs":[{"data":{"text/plain":["['when',\n"," 'a',\n"," 'father',\n"," 'is',\n"," 'dysfunctional',\n"," 'and',\n"," 'is',\n"," 'so',\n"," 'selfish',\n"," 'he',\n"," 'drags',\n"," 'his',\n"," 'kids',\n"," 'into',\n"," 'his',\n"," 'dysfunction',\n"," '.',\n"," '#run']"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["tweet_token[0]"]},{"cell_type":"code","execution_count":null,"id":"jewish-throat","metadata":{"id":"jewish-throat","outputId":"ed561bcb-deff-47c7-c090-a83dce262af9"},"outputs":[{"data":{"text/plain":["['father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', 'run']"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["del_stop(tweet_token[0])"]},{"cell_type":"code","execution_count":null,"id":"objective-detail","metadata":{"id":"objective-detail","outputId":"d684731a-ab17-417e-f4ae-4e5389b6fb3c"},"outputs":[{"data":{"text/plain":["['father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', 'run']"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["clean_tweets = [del_stop(t) for t in tweet_token]\n","clean_tweets[0]"]},{"cell_type":"markdown","id":"fundamental-disease","metadata":{"id":"fundamental-disease"},"source":["### Check out the top terms in the tweets"]},{"cell_type":"code","execution_count":null,"id":"previous-atmosphere","metadata":{"id":"previous-atmosphere"},"outputs":[],"source":["from collections import Counter"]},{"cell_type":"code","execution_count":null,"id":"mobile-appendix","metadata":{"id":"mobile-appendix"},"outputs":[],"source":["term_list = []\n","for tweet in clean_tweets:\n","    term_list.extend(tweet)\n","#print(term_list)"]},{"cell_type":"code","execution_count":null,"id":"bulgarian-league","metadata":{"id":"bulgarian-league"},"outputs":[],"source":["words = []\n","num = []\n","con = Counter(term_list)\n","common = con.most_common(10)\n","for w,n in common:\n","    words.append(w)\n","    num.append(n)"]},{"cell_type":"code","execution_count":null,"id":"christian-point","metadata":{"id":"christian-point"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"id":"returning-gossip","metadata":{"id":"returning-gossip","outputId":"e6fadba1-5797-461c-f60b-a3dff2846e42"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 576x576 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.rcParams[\"figure.figsize\"] = (8,8)\n","plt.bar(words, num);\n","plt.title(\"Most Common Words & their Frequencies\" );"]},{"cell_type":"markdown","id":"distributed-reunion","metadata":{"id":"distributed-reunion"},"source":["### Joining tweets"]},{"cell_type":"code","execution_count":null,"id":"colored-diagnosis","metadata":{"id":"colored-diagnosis","outputId":"dca50a5e-2075-486d-f821-86bf353e7f95"},"outputs":[{"data":{"text/plain":["['father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', 'run']"]},"execution_count":134,"metadata":{},"output_type":"execute_result"}],"source":["clean_tweets[0]"]},{"cell_type":"code","execution_count":null,"id":"prescription-vienna","metadata":{"id":"prescription-vienna","outputId":"cf0a1244-4a76-44ed-be32-e9e4cd3cbfc5"},"outputs":[{"data":{"text/plain":["'father dysfunctional selfish drags kids dysfunction run'"]},"execution_count":136,"metadata":{},"output_type":"execute_result"}],"source":["tweets_clean = [\" \".join(t) for t in clean_tweets]\n","tweets_clean[0]"]},{"cell_type":"code","execution_count":null,"id":"terminal-defeat","metadata":{"id":"terminal-defeat"},"outputs":[],"source":["X = tweets_clean\n","y = df.label.values"]},{"cell_type":"code","execution_count":null,"id":"horizontal-highway","metadata":{"id":"horizontal-highway","outputId":"f1b9f74f-c863-4d12-b0e5-c5b66f51c28c"},"outputs":[{"data":{"text/plain":["array([0, 0, 0, ..., 0, 1, 0])"]},"execution_count":140,"metadata":{},"output_type":"execute_result"}],"source":["y"]},{"cell_type":"code","execution_count":null,"id":"weighted-leader","metadata":{"id":"weighted-leader"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 3)"]},{"cell_type":"code","execution_count":null,"id":"japanese-creation","metadata":{"id":"japanese-creation","outputId":"7de05f5b-98e3-4e16-a94a-69d63cbc43fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["22373 9589\n"]}],"source":["print(len(X_train), len(X_test))"]},{"cell_type":"markdown","id":"anonymous-warehouse","metadata":{"id":"anonymous-warehouse"},"source":["### TF-IDF"]},{"cell_type":"code","execution_count":null,"id":"warming-closer","metadata":{"id":"warming-closer"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer"]},{"cell_type":"code","execution_count":null,"id":"dominican-thinking","metadata":{"id":"dominican-thinking"},"outputs":[],"source":["tf = TfidfVectorizer(max_features = 5000)"]},{"cell_type":"code","execution_count":null,"id":"hollow-student","metadata":{"id":"hollow-student"},"outputs":[],"source":["x_train_tf = tf.fit_transform(X_train)\n","x_test_tf = tf.transform(X_test)"]},{"cell_type":"code","execution_count":null,"id":"described-romantic","metadata":{"id":"described-romantic","outputId":"c3805d0b-4706-445f-d0bd-3effc4baf7c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["(22373, 5000) (9589, 5000)\n"]}],"source":["print(x_train_tf.shape, x_test_tf.shape)"]},{"cell_type":"markdown","id":"finished-atmosphere","metadata":{"id":"finished-atmosphere"},"source":["### Ordinary Logistic Regression"]},{"cell_type":"code","execution_count":null,"id":"corporate-france","metadata":{"id":"corporate-france","outputId":"4fa797a3-1435-472a-b52d-2a99f472d7a9"},"outputs":[{"data":{"text/plain":["LogisticRegression(random_state=0)"]},"execution_count":159,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.linear_model import LogisticRegression\n","\n","lg = LogisticRegression(random_state=0)\n","lg.fit(x_train_tf, y_train)"]},{"cell_type":"code","execution_count":null,"id":"valuable-firmware","metadata":{"id":"valuable-firmware"},"outputs":[],"source":["y_train_pred = lg.predict(x_train_tf)\n","y_test_pred = lg.predict(x_test_tf)"]},{"cell_type":"code","execution_count":null,"id":"absolute-farmer","metadata":{"id":"absolute-farmer"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, classification_report"]},{"cell_type":"code","execution_count":null,"id":"passing-hostel","metadata":{"id":"passing-hostel","outputId":"2ec4cf8b-136a-4757-991d-187f89287c25"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Set Accuracy: 95.48 \n","Testing Set Accuracy: 94.89 \n"]}],"source":["print(\"Training Set Accuracy: %2.2f \" % (accuracy_score(y_train, y_train_pred)*100))\n","print(\"Testing Set Accuracy: %2.2f \" % (accuracy_score(y_test, y_test_pred)*100))"]},{"cell_type":"code","execution_count":null,"id":"sustained-jason","metadata":{"id":"sustained-jason","outputId":"5c7ab978-20b0-4ebd-9af8-681413d9d1ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.95      1.00      0.97      8924\n","           1       0.89      0.30      0.45       665\n","\n","    accuracy                           0.95      9589\n","   macro avg       0.92      0.65      0.71      9589\n","weighted avg       0.95      0.95      0.94      9589\n","\n"]}],"source":["print(classification_report(y_test, y_test_pred))"]},{"cell_type":"markdown","id":"subtle-insurance","metadata":{"id":"subtle-insurance"},"source":["#### F1-Score is low for 1 (hate class), this is due to the classes imbalance "]},{"cell_type":"markdown","id":"applicable-builder","metadata":{"id":"applicable-builder"},"source":["### Adjusted Logistic Regression + resolving class imbalance"]},{"cell_type":"code","execution_count":null,"id":"central-election","metadata":{"id":"central-election","outputId":"b29326cd-3545-4d41-c0f1-b858c18f4618"},"outputs":[{"data":{"text/plain":["LogisticRegression(class_weight='balanced', random_state=0)"]},"execution_count":170,"metadata":{},"output_type":"execute_result"}],"source":["lg2 = LogisticRegression(class_weight = 'balanced', random_state=0)\n","lg2.fit(x_train_tf, y_train)\n"]},{"cell_type":"code","execution_count":null,"id":"entire-committee","metadata":{"id":"entire-committee"},"outputs":[],"source":["y_train_pred = lg2.predict(x_train_tf)\n","y_test_pred = lg2.predict(x_test_tf)"]},{"cell_type":"code","execution_count":null,"id":"tough-davis","metadata":{"id":"tough-davis","outputId":"2ba15397-66dc-49ed-e889-4e7ca8d9a415"},"outputs":[{"name":"stdout","output_type":"stream","text":["Adjusted Logistic Regression + resolving class imbalance\n","\n","Training Set Accuracy: 95.33 \n","Testing Set Accuracy: 92.57 \n"]}],"source":["print(\"Adjusted Logistic Regression + resolving class imbalance\\n\")\n","print(\"Training Set Accuracy: %2.2f \" % (accuracy_score(y_train, y_train_pred)*100))\n","print(\"Testing Set Accuracy: %2.2f \" % (accuracy_score(y_test, y_test_pred)*100))"]},{"cell_type":"code","execution_count":null,"id":"dental-party","metadata":{"id":"dental-party","outputId":"ace87634-9020-4aa9-fb61-77a473abf42f"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.95      0.97     20796\n","           1       0.60      0.97      0.75      1577\n","\n","    accuracy                           0.95     22373\n","   macro avg       0.80      0.96      0.86     22373\n","weighted avg       0.97      0.95      0.96     22373\n","\n"]}],"source":["print(classification_report(y_train, y_train_pred))"]},{"cell_type":"code","execution_count":null,"id":"convertible-investing","metadata":{"id":"convertible-investing","outputId":"4f909d05-261e-410f-f09e-12865319ddf3"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.98      0.94      0.96      8924\n","           1       0.48      0.75      0.58       665\n","\n","    accuracy                           0.93      9589\n","   macro avg       0.73      0.85      0.77      9589\n","weighted avg       0.95      0.93      0.93      9589\n","\n"]}],"source":["print(classification_report(y_test, y_test_pred))"]},{"cell_type":"markdown","id":"absent-reviewer","metadata":{"id":"absent-reviewer"},"source":["#### There's a significant different between the F1-Scores of the train and test datasets, this could imply the represent of overfitting "]},{"cell_type":"markdown","id":"level-instrumentation","metadata":{"id":"level-instrumentation"},"source":["### Regularization and Hyperparameter Tuning"]},{"cell_type":"code","execution_count":null,"id":"requested-repeat","metadata":{"id":"requested-repeat"},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV"]},{"cell_type":"code","execution_count":null,"id":"valid-sweden","metadata":{"id":"valid-sweden"},"outputs":[],"source":["param_grid = {\n","    'C': [0.001,0.01,0.1,1,10,100],\n","    'penalty': [\"l1\",\"l2\", \"elasticnet\"]\n","}\n","\n","lg3 = LogisticRegression(class_weight = 'balanced', random_state=0)\n","#lg3.fit(x_train_tf, y_train)"]},{"cell_type":"code","execution_count":null,"id":"humanitarian-survivor","metadata":{"id":"humanitarian-survivor"},"outputs":[],"source":["gs = GridSearchCV(estimator = lg3, param_grid = param_grid, \n","                  cv = StratifiedKFold(4), n_jobs = -1, \n","                  verbose = 1, scoring = \"recall\" )"]},{"cell_type":"code","execution_count":null,"id":"caring-record","metadata":{"id":"caring-record","outputId":"de7113a2-3c16-429e-8e22-00ee7fc2ca36"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 4 folds for each of 18 candidates, totalling 72 fits\n"]},{"name":"stderr","output_type":"stream","text":["/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:925: UserWarning: One or more of the test scores are non-finite: [       nan 0.66200443        nan        nan 0.70131883        nan\n","        nan 0.76473527        nan        nan 0.77362494        nan\n","        nan 0.73748153        nan        nan 0.69183801        nan]\n","  category=UserWarning\n"]},{"data":{"text/plain":["GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n","             estimator=LogisticRegression(class_weight='balanced',\n","                                          random_state=0),\n","             n_jobs=-1,\n","             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n","                         'penalty': ['l1', 'l2', 'elasticnet']},\n","             scoring='recall', verbose=1)"]},"execution_count":190,"metadata":{},"output_type":"execute_result"}],"source":["gs.fit(x_train_tf, y_train)"]},{"cell_type":"code","execution_count":null,"id":"married-torture","metadata":{"id":"married-torture","outputId":"51ba8c69-e960-4c5d-80ff-001341ec6b74"},"outputs":[{"data":{"text/plain":["{'C': 1, 'penalty': 'l2'}"]},"execution_count":191,"metadata":{},"output_type":"execute_result"}],"source":["gs.best_params_"]},{"cell_type":"code","execution_count":null,"id":"quantitative-times","metadata":{"id":"quantitative-times"},"outputs":[],"source":["y_best_pred_train = gs.predict(x_train_tf)\n","y_best_pred_test = gs.predict(x_test_tf)"]},{"cell_type":"code","execution_count":null,"id":"prime-officer","metadata":{"id":"prime-officer","outputId":"64893e22-64dc-4be9-f120-95576bd728ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.95      0.97     20796\n","           1       0.60      0.97      0.75      1577\n","\n","    accuracy                           0.95     22373\n","   macro avg       0.80      0.96      0.86     22373\n","weighted avg       0.97      0.95      0.96     22373\n","\n"]}],"source":["print(classification_report(y_train, y_best_pred_train))"]},{"cell_type":"code","execution_count":null,"id":"enabling-youth","metadata":{"id":"enabling-youth","outputId":"c80dc973-518b-4e8e-f36b-39a4704e2a72"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.98      0.94      0.96      8924\n","           1       0.48      0.75      0.58       665\n","\n","    accuracy                           0.93      9589\n","   macro avg       0.73      0.85      0.77      9589\n","weighted avg       0.95      0.93      0.93      9589\n","\n"]}],"source":["print(classification_report(y_test, y_best_pred_test))"]},{"cell_type":"markdown","id":"listed-stevens","metadata":{"id":"listed-stevens"},"source":["### Random Forest"]},{"cell_type":"code","execution_count":null,"id":"mysterious-stake","metadata":{"id":"mysterious-stake","outputId":"83c84d04-3d26-4684-f926-3a5d6510d6ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"]}],"source":["from sklearn.model_selection import RandomizedSearchCV\n","# Number of trees in random forest\n","n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n","# Number of features to consider at every split\n","max_features = ['auto', 'sqrt']\n","# Maximum number of levels in tree\n","max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n","max_depth.append(None)\n","# Minimum number of samples required to split a node\n","min_samples_split = [2, 5, 10]\n","# Minimum number of samples required at each leaf node\n","min_samples_leaf = [1, 2, 4]\n","# Method of selecting samples for training each tree\n","bootstrap = [True, False]\n","# Create the random grid\n","random_grid = {'n_estimators': n_estimators,\n","               'max_features': max_features,\n","               'max_depth': max_depth,\n","               'min_samples_split': min_samples_split,\n","               'min_samples_leaf': min_samples_leaf,\n","               'bootstrap': bootstrap}\n","\n","\n","print(random_grid)"]},{"cell_type":"code","execution_count":null,"id":"legislative-barrel","metadata":{"id":"legislative-barrel"},"outputs":[],"source":["from sklearn.ensemble import RandomForestRegressor"]},{"cell_type":"code","execution_count":null,"id":"variable-fortune","metadata":{"id":"variable-fortune","outputId":"0c962924-b8ba-4c5e-c7f8-97653e26a659"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"]},{"data":{"text/plain":["RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,\n","                   n_jobs=-1,\n","                   param_distributions={'bootstrap': [True, False],\n","                                        'max_depth': [10, 20, 30, 40, 50, 60,\n","                                                      70, 80, 90, 100, 110,\n","                                                      None],\n","                                        'max_features': ['auto', 'sqrt'],\n","                                        'min_samples_leaf': [1, 2, 4],\n","                                        'min_samples_split': [2, 5, 10],\n","                                        'n_estimators': [200, 400, 600, 800,\n","                                                         1000, 1200, 1400, 1600,\n","                                                         1800, 2000]},\n","                   random_state=42, verbose=2)"]},"execution_count":211,"metadata":{},"output_type":"execute_result"}],"source":["# Use the random grid to search for best hyperparameters\n","# First create the base model to tune\n","rf = RandomForestRegressor()\n","# Random search of parameters, using 3 fold cross validation, \n","# search across 100 different combinations, and use all available cores\n","rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n","                               n_iter = 100, cv = 3, verbose=1, random_state=42, n_jobs = -1)\n","# Fit the random search model\n","rf_random.fit(x_train_tf, y_train)"]},{"cell_type":"code","execution_count":null,"id":"arabic-magnitude","metadata":{"id":"arabic-magnitude","outputId":"ee2431a0-61d5-4de2-8059-aaa1db54ba50"},"outputs":[{"data":{"text/plain":["{'n_estimators': 1600,\n"," 'min_samples_split': 10,\n"," 'min_samples_leaf': 1,\n"," 'max_features': 'sqrt',\n"," 'max_depth': None,\n"," 'bootstrap': True}"]},"execution_count":213,"metadata":{},"output_type":"execute_result"}],"source":["rf_random.best_params_"]},{"cell_type":"code","execution_count":null,"id":"statewide-confusion","metadata":{"id":"statewide-confusion"},"outputs":[],"source":["y_best_pred_train_rf2 = rf_random.predict(x_train_tf)\n","y_best_pred_test_rf2 = rf_random.predict(x_test_tf)"]},{"cell_type":"code","execution_count":null,"id":"cardiac-huntington","metadata":{"id":"cardiac-huntington","outputId":"60c4bab3-e0fa-4668-f5de-74b911c7d560"},"outputs":[{"data":{"text/plain":["array([0.        , 0.07755819, 0.00275387, 0.00306671, 0.00195771,\n","       0.        , 0.00868919, 0.        , 0.        , 0.06561225])"]},"execution_count":238,"metadata":{},"output_type":"execute_result"}],"source":["y_best_pred_train_rf[:10]"]},{"cell_type":"code","execution_count":null,"id":"naughty-continuity","metadata":{"id":"naughty-continuity"},"outputs":[],"source":["p_train = [1 if p >= 0.4 else 0 for p in y_best_pred_train_rf2]\n","p_test = [1 if p >= 0.4 else 0 for p in y_best_pred_test_rf2]"]},{"cell_type":"code","execution_count":null,"id":"czech-respect","metadata":{"id":"czech-respect","outputId":"71c26637-05c1-42eb-e409-359e887c4d30"},"outputs":[{"data":{"text/plain":["Counter({0: 20827, 1: 1546})"]},"execution_count":281,"metadata":{},"output_type":"execute_result"}],"source":["con2 = Counter(p_train)\n","con2"]},{"cell_type":"code","execution_count":null,"id":"responsible-audit","metadata":{"id":"responsible-audit","outputId":"8dfbd7ea-a056-44cf-a72f-09c521629c9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     20796\n","           1       0.96      0.94      0.95      1577\n","\n","    accuracy                           0.99     22373\n","   macro avg       0.98      0.97      0.97     22373\n","weighted avg       0.99      0.99      0.99     22373\n","\n"]}],"source":["print(classification_report(y_train, p_train))"]},{"cell_type":"code","execution_count":null,"id":"natural-backup","metadata":{"id":"natural-backup","outputId":"27a27e0f-660a-41eb-f910-27f70517c2c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.97      0.98      0.98      8924\n","           1       0.70      0.58      0.64       665\n","\n","    accuracy                           0.95      9589\n","   macro avg       0.84      0.78      0.81      9589\n","weighted avg       0.95      0.95      0.95      9589\n","\n"]}],"source":["print(classification_report(y_test, p_test))"]},{"cell_type":"code","execution_count":null,"id":"covered-tuning","metadata":{"id":"covered-tuning","outputId":"535528dd-40f8-4f73-b82c-e4bdb064e973"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Set Accuracy: 99.24 \n","Testing Set Accuracy: 95.39 \n"]}],"source":["print(\"Training Set Accuracy: %2.2f \" % (accuracy_score(y_train, p_train)*100))\n","print(\"Testing Set Accuracy: %2.2f \" % (accuracy_score(y_test, p_test)*100))"]},{"cell_type":"code","execution_count":null,"id":"circular-combination","metadata":{"id":"circular-combination","outputId":"8671d027-cbfb-4450-9aaf-6a57d9e37169"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Set F1-Score: 99.24 \n","Testing Set F1-Score: 95.19 \n"]}],"source":["from sklearn.metrics import f1_score\n","print(\"Training Set F1-Score: %2.2f \" % (f1_score(y_train, p_train, average='weighted')*100))\n","print(\"Testing Set F1-Score: %2.2f \" % (f1_score(y_test, p_test, average='weighted')*100))"]},{"cell_type":"markdown","id":"critical-funeral","metadata":{"id":"critical-funeral"},"source":["#### I accidently trained using a Regressor instead of a Classifier. This realization came after 6 hours of Grid Search"]},{"cell_type":"code","execution_count":null,"id":"prospective-password","metadata":{"id":"prospective-password"},"outputs":[],"source":["pare = {'n_estimators': 1600,\n"," 'min_samples_split': 10,\n"," 'min_samples_leaf': 1,\n"," 'max_features': 'sqrt',\n"," 'max_depth': None,\n"," 'bootstrap': True}"]},{"cell_type":"code","execution_count":null,"id":"single-swedish","metadata":{"id":"single-swedish"},"outputs":[],"source":["?RandomForestClassifier"]},{"cell_type":"code","execution_count":null,"id":"through-tiger","metadata":{"id":"through-tiger","outputId":"f34238a0-7399-42ed-d5e1-30e359931d68"},"outputs":[{"data":{"text/plain":["RandomForestClassifier(max_features='sqrt', min_samples_split=10,\n","                       n_estimators=1600)"]},"execution_count":230,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.ensemble import RandomForestClassifier\n","clf = RandomForestClassifier(n_estimators= 1600, min_samples_split= 10, min_samples_leaf= 1,\n","                             max_features= 'sqrt',max_depth= None, bootstrap= True)\n","\n","clf.fit(x_train_tf, y_train)"]},{"cell_type":"code","execution_count":null,"id":"medieval-pulse","metadata":{"id":"medieval-pulse"},"outputs":[],"source":["y_best_pred_train_clf = clf.predict(x_train_tf)\n","y_best_pred_test_clf = clf.predict(x_test_tf)"]},{"cell_type":"code","execution_count":null,"id":"declared-protocol","metadata":{"id":"declared-protocol","outputId":"2315c336-5821-4b02-d6c8-29b454160672"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99     20796\n","           1       0.98      0.86      0.92      1577\n","\n","    accuracy                           0.99     22373\n","   macro avg       0.99      0.93      0.96     22373\n","weighted avg       0.99      0.99      0.99     22373\n","\n"]}],"source":["print(classification_report(y_train, y_best_pred_train_clf))"]},{"cell_type":"code","execution_count":null,"id":"hidden-diana","metadata":{"id":"hidden-diana","outputId":"6bae3a3e-a1ff-4c55-b014-18cc7c49693c"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.96      0.99      0.98      8924\n","           1       0.79      0.52      0.62       665\n","\n","    accuracy                           0.96      9589\n","   macro avg       0.88      0.75      0.80      9589\n","weighted avg       0.95      0.96      0.95      9589\n","\n"]}],"source":["print(classification_report(y_test, y_best_pred_test_clf))"]},{"cell_type":"code","execution_count":null,"id":"located-freedom","metadata":{"id":"located-freedom","outputId":"8daac9d0-7bdb-4867-f501-cc97eeac2f83"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Set Accuracy: 98.90 \n","Testing Set Accuracy: 95.67 \n"]}],"source":["print(\"Training Set Accuracy: %2.2f \" % (accuracy_score(y_train, y_best_pred_train_clf)*100))\n","print(\"Testing Set Accuracy: %2.2f \" % (accuracy_score(y_test, y_best_pred_test_clf)*100))"]},{"cell_type":"code","execution_count":null,"id":"occupied-vault","metadata":{"id":"occupied-vault","outputId":"783e139e-59fa-4620-a2f1-1aa8e58ce82e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Set F1-Score: 98.87 \n","Testing Set F1-Score: 95.25 \n"]}],"source":["from sklearn.metrics import f1_score\n","print(\"Training Set F1-Score: %2.2f \" % (f1_score(y_train, y_best_pred_train_rf2, average='weighted')*100))\n","print(\"Testing Set F1-Score: %2.2f \" % (f1_score(y_test, y_best_pred_test_rf2, average='weighted')*100))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}